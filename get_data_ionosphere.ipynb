{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f55e4fa-af8c-45fa-98c6-b2405992bd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from multiprocessing import Process, Pool\n",
    "from dateutil.relativedelta import *\n",
    "import dateutil.parser\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fc5210b-6f5d-4094-95ce-110bf12208f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPS_info = pd.read_csv(\"IGSNetwork.csv\")\n",
    "df_stations = GPS_info[\"#StationName\"].copy()\n",
    "df_lat = GPS_info[\"Latitude\"].array\n",
    "df_long =  GPS_info[\"Longitude\"].array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d0e2fe5-d698-4afa-b647-9962767763db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between China Shangai and Max Hermosillo is:  11217.42914961266\n"
     ]
    }
   ],
   "source": [
    "# Import the geodesic module from geopy library \n",
    "from geopy.distance import geodesic as GD\n",
    " # For the specified locations, load their latitude and longitude data.\n",
    "china_coor = (37.970250, 23.722544)#(31.19, 121.50)\n",
    "mex_coor  = (29.08, -110.96)\n",
    "closest_stations_n = 8\n",
    "#Finally, print the distance between the two sites in kilometers.\n",
    "print(\"The distance between China Shangai and Max Hermosillo is: \", GD(china_coor,mex_coor).km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c265959-ab72-4b73-8ecb-40615bd53eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_china = pd.DataFrame({\"CHINA_DIST\":[GD((current_lat, current_lot),china_coor).km for (current_lat, current_lot) in zip(df_lat,df_long)]})\n",
    "df_mex = pd.DataFrame({\"MEX_DIST\":[GD((current_lat, current_lot),mex_coor).km for (current_lat, current_lot) in zip(df_lat,df_long)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5c54a86-3d28-4833-a8ee-53b1a3cc2123",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.concat([df_stations, df_china.reindex(df_stations.index), df_mex.reindex(df_stations.index)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "591bab31-9c24-4267-bce2-219a94988231",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_china = stations.sort_values(by=\"CHINA_DIST\")[0:closest_stations_n].index\n",
    "index_mex = stations.sort_values(by=\"MEX_DIST\")[0:closest_stations_n].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e09ad01-419c-4023-9871-edc87628f056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([112, 183, 311, 399, 182, 444, 242, 244, 43, 333, 103, 270, 252,\n",
       "            335, 483, 39],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_china.append(index_mex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5505a533-fe7c-4459-8117-5cb9825ea3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    #StationName    CHINA_DIST      MEX_DIST\n",
      "112    DYNG00GRC     21.998436  11219.651156\n",
      "183    IZMI00TUR    298.070372  11360.992630\n",
      "311    ORID00MKD    431.445158  10787.239528\n",
      "399    SOFI00BGR    509.961189  10804.386024\n",
      "182    ISTA00TUR    572.848723  11213.695325\n",
      "444    TUBI00TUR    584.112065  11263.340508\n",
      "242    MAT100ITA    674.080016  10593.761795\n",
      "244    MATG00ITA    674.080016  10593.761795\n",
      "43     BLYT00USA  10994.094203    616.276910\n",
      "333    PIE100USA  10589.499324    638.520030\n",
      "103    DHLG00USA  11067.067337    663.080189\n",
      "270    MONP00USA  11144.884169    671.228821\n",
      "252    MDO100USA  10673.793090    693.834191\n",
      "335    PIN100USA  11077.998663    725.155434\n",
      "483    WIDC00USA  11044.083342    745.424342\n",
      "39     BILL00USA  11109.875277    765.425629\n"
     ]
    }
   ],
   "source": [
    "current_stations = stations.iloc[index_china.append(index_mex),:]\n",
    "print(current_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12b6c7a1-4116-48f6-92f5-f2261625c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pre_path = \"D://dataframe\"\n",
    "file_name = \"{station}_{year}_{month}_{day}.csv\"\n",
    "headers = ['dates', 'tec']\n",
    "dtypes = {'dates': 'str', 'tec': 'float'}\n",
    "parse_dates = ['dates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "251c9d36-ef8c-40e8-8b5e-97beaec2f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_and_erase(path, station):\n",
    "    headers = ['dates', 'tec']\n",
    "    dtypes = {'dates': 'str', 'tec': 'float'}\n",
    "    parse_dates = ['dates']\n",
    "    df_output = pd.DataFrame()\n",
    "    for file in Path(\".\").glob(\"*{station}*\".format(station=station)):\n",
    "        with file as f:\n",
    "            current_df_output = pd.read_csv(f, header=None,  comment='#',sep = ' ',names=headers, dtype=dtypes, parse_dates=parse_dates)\n",
    "            current_df_output = current_df_output.set_index(\"dates\")\n",
    "            df_output = pd.concat([df_output, current_df_output])\n",
    "        df_output.to_csv(path , compression = 'xz')\n",
    "        file.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "098f4762-4cb9-4bf3-8dd5-819bee1385d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return None if hte file is in the fs\n",
    "def get_new_path(day, station):\n",
    "    current_year = day.strftime('%Y')\n",
    "    current_month = day.strftime('%m')\n",
    "    current_path = pre_path + \"/\" + str(station) \n",
    "    current_path_year = current_path + \"/\" + current_year\n",
    "    current_path_year_month = current_path_year + \"/\" + current_month\n",
    "    current_path_year_day = current_path_year_month + \"/\" + file_name.format(station=station, year = current_year, month=current_month, day = day.strftime('%d'))\n",
    "    \n",
    "    if  Path(current_path).is_dir():\n",
    "        if  Path(current_path_year).is_dir():\n",
    "            if Path(current_path_year_month).is_dir():\n",
    "                if Path(current_path_year_day).is_file():\n",
    "                    return None\n",
    "                else:\n",
    "                    return current_path_year_day\n",
    "            else:\n",
    "                os.mkdir(current_path_year_month)\n",
    "                return current_path_year_day\n",
    "        else:\n",
    "            os.mkdir(current_path_year)\n",
    "            os.mkdir(current_path_year_month)\n",
    "            return current_path_year_day\n",
    "    else:\n",
    "        os.mkdir(current_path)\n",
    "        os.mkdir(current_path_year)\n",
    "        os.mkdir(current_path_year_month)\n",
    "        return current_path_year_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18a3dbad-a5fd-48d8-ace9-cbadbaf2ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tec_station(start_day, end_day, station):\n",
    "    all_days = [start_day+timedelta(days=x) for x in range((end_day-start_day).days)]\n",
    "    for day in all_days:\n",
    "        current_year = day.year\n",
    "        current_month = day.month\n",
    "        new_path = get_new_path(day, station)\n",
    "        if new_path != None:\n",
    "            print(str(station) + \" -- \" + str(day.strftime('%Y-%m-%d')))\n",
    "            result = subprocess.run([\"ionolabtec.exe\", str(station), str(day.strftime('%Y-%m-%d'))], capture_output=True)\n",
    "            if \"does not exist.\\\\r\\\\n\" in str(result.stdout):\n",
    "                print(str(station) + \" is not valid\")\n",
    "            read_csv_and_erase(new_path, station)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d860202-c312-4a13-8b40-cd2c8b2006a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DYNG00GRC -- 2018-01-01IZMI00TUR -- 2018-01-01\n",
      "\n",
      "ORID00MKD -- 2018-01-01\n",
      "SOFI00BGR -- 2018-01-01\n",
      "ISTA00TUR -- 2018-01-01\n",
      "MATG00ITA -- 2018-01-01MAT100ITA -- 2018-01-01BLYT00USA -- 2018-01-01TUBI00TUR -- 2018-01-01\n",
      "\n",
      "\n",
      "\n",
      "PIE100USA -- 2018-01-01\n",
      "ISTA00TUR -- 2018-01-02\n",
      "MATG00ITA -- 2018-01-02\n",
      "MAT100ITA -- 2018-01-02\n",
      "DYNG00GRC -- 2018-01-02\n",
      "ISTA00TUR -- 2018-01-03\n",
      "DYNG00GRC -- 2018-01-03\n",
      "MATG00ITA -- 2018-01-03\n",
      "MAT100ITA -- 2018-01-03\n",
      "IZMI00TUR is not valid\n",
      "BLYT00USA is not validTUBI00TUR is not valid\n",
      "\n",
      "SOFI00BGR is not validIZMI00TUR -- 2018-01-02\n",
      "\n",
      "TUBI00TUR -- 2018-01-02BLYT00USA -- 2018-01-02\n",
      "\n",
      "SOFI00BGR -- 2018-01-02\n",
      "MAT100ITA -- 2018-01-04\n",
      "ORID00MKD is not valid\n",
      "ORID00MKD -- 2018-01-02\n",
      "ISTA00TUR -- 2018-01-04\n",
      "DYNG00GRC -- 2018-01-04\n",
      "PIE100USA -- 2018-01-02\n",
      "MATG00ITA -- 2018-01-04\n",
      "IZMI00TUR is not valid\n",
      "IZMI00TUR -- 2018-01-03\n",
      "SOFI00BGR is not valid\n",
      "SOFI00BGR -- 2018-01-03\n",
      "TUBI00TUR is not valid\n",
      "TUBI00TUR -- 2018-01-03\n",
      "BLYT00USA is not valid\n",
      "BLYT00USA -- 2018-01-03\n",
      "ORID00MKD is not valid\n",
      "ORID00MKD -- 2018-01-03\n",
      "Finished\n",
      "DHLG00USA -- 2018-01-01\n",
      "Finished\n",
      "MONP00USA -- 2018-01-01\n",
      "Finished\n",
      "MDO100USA -- 2018-01-01\n",
      "Finished\n",
      "PIN100USA -- 2018-01-01\n",
      "PIE100USA -- 2018-01-03\n",
      "BLYT00USA is not valid\n",
      "BLYT00USA -- 2018-01-04\n",
      "SOFI00BGR is not valid\n",
      "SOFI00BGR -- 2018-01-04\n",
      "IZMI00TUR is not valid\n",
      "IZMI00TUR -- 2018-01-04\n",
      "IZMI00TUR is not valid\n",
      "Finished\n",
      "WIDC00USA -- 2018-01-01\n",
      "SOFI00BGR is not valid\n",
      "Finished\n",
      "BILL00USA -- 2018-01-01\n",
      "BLYT00USA is not valid\n",
      "Finished\n",
      "BILL00USA is not valid\n",
      "BILL00USA -- 2018-01-02\n",
      "WIDC00USA is not valid\n",
      "WIDC00USA -- 2018-01-02\n",
      "TUBI00TUR is not valid\n",
      "TUBI00TUR -- 2018-01-04\n",
      "ORID00MKD is not valid\n",
      "ORID00MKD -- 2018-01-04\n",
      "DHLG00USA is not valid\n",
      "DHLG00USA -- 2018-01-02\n",
      "MONP00USA is not valid\n",
      "MONP00USA -- 2018-01-02\n",
      "MONP00USA is not valid\n",
      "MONP00USA -- 2018-01-03\n",
      "DHLG00USA is not valid\n",
      "DHLG00USA -- 2018-01-03\n",
      "DHLG00USA is not valid\n",
      "DHLG00USA -- 2018-01-04\n",
      "MONP00USA is not valid\n",
      "MONP00USA -- 2018-01-04\n",
      "BILL00USA is not valid\n",
      "BILL00USA -- 2018-01-03\n",
      "WIDC00USA is not valid\n",
      "WIDC00USA -- 2018-01-03\n",
      "PIN100USA is not valid\n",
      "PIN100USA -- 2018-01-02\n",
      "MDO100USA -- 2018-01-02\n",
      "PIE100USA -- 2018-01-04\n",
      "ORID00MKD is not valid\n",
      "Finished\n",
      "BILL00USA is not valid\n",
      "BILL00USA -- 2018-01-04\n",
      "WIDC00USA is not valid\n",
      "WIDC00USA -- 2018-01-04\n",
      "PIN100USA is not valid\n",
      "PIN100USA -- 2018-01-03\n",
      "MDO100USA -- 2018-01-03\n",
      "Finished\n",
      "BILL00USA is not valid\n",
      "Finished\n",
      "WIDC00USA is not valid\n",
      "Finished\n",
      "PIN100USA is not valid\n",
      "PIN100USA -- 2018-01-04\n",
      "TUBI00TUR is not valid\n",
      "Finished\n",
      "MONP00USA is not valid\n",
      "Finished\n",
      "DHLG00USA is not valid\n",
      "Finished\n",
      "MDO100USA -- 2018-01-04\n",
      "PIN100USA is not valid\n",
      "Finished\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import urllib.request\n",
    "from geopy.distance import geodesic as GD\n",
    "stations =  list(df_stations[0:10])\n",
    "stations = current_stations[\"#StationName\"]\n",
    "def f(station):\n",
    "    start_day = datetime(2018, 1, 1).date()\n",
    "    end_day = datetime(2018, 1, 5).date()\n",
    "    get_tec_station(start_day,end_day, station)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers = 10) as executor:\n",
    "\n",
    "    future_to_url = {executor.submit(f, station): station for station in stations}\n",
    "    for future in concurrent.futures.as_completed(future_to_url):\n",
    "        url = future_to_url[future]\n",
    "        try:\n",
    "            data = future.result()\n",
    "        except Exception as exc:\n",
    "            print('%r generated an exception: %s' % (url, exc))\n",
    "        else:\n",
    "            print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "67f7faea-52eb-4a15-b1d9-43be2d9abe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Including necessary packages\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d7e4fa9-7f74-4fd8-90f7-0d27d5243824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking on queries function\n",
    "def checking_by_mail(mail):\n",
    "    \"\"\"\n",
    "    checking all accessible information about queries made by <mail>\n",
    "    input - <mail> string type email address to check\n",
    "    output - list of dictionaries with all information about every query\n",
    "    \"\"\"\n",
    "    rq = requests.post(\"https://simurg.iszf.irk.ru/api\", \n",
    "                        json={\"method\": \"check\", \n",
    "                        \"args\": {\"email\": mail}\n",
    "                              }\n",
    "                        )\n",
    "    return rq.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33dcd321-d7b2-4050-b3cf-30c9e569568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing results for email\n",
    "email = 'ccd532@uma.es'\n",
    "for i in checking_by_mail(email):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73da268c-89ef-4008-a60b-8d55ab3dbcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to show progrees of downloading data\n",
    "def progress_print(count, block_size, total_size):\n",
    "    prc = (count * block_size) / (total_size / 100)\n",
    "    print(\"{0:3d}/100%\".format(int(prc)), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96de05e3-5875-4952-82ec-3301f93ba694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to downloading data in same path as notebook \n",
    "def download_data(query,type_q,download_t):\n",
    "    \"\"\"\n",
    "    downloading data based on query dictionary\n",
    "    input - <query> query dictionary, \n",
    "            <type_q> string type what type of query download (either 'series' or 'map'), \n",
    "            <download_t> string type what to download ('zip' zip archive of maps/series or 'h5' all data in hdf type)\n",
    "    output - Results of downloading\n",
    "    \"\"\"    \n",
    "    print('id:', query['id'],\n",
    "          'type:', query['type'],\n",
    "          'status:', query['status'],\n",
    "          'site:', query['site'])\n",
    "    if query['type'] == type_q and query['status'] == 'done':\n",
    "        directory = os.getcwd()\n",
    "        file_name = 'example.'+download_t\n",
    "        if download_t == 'h5':\n",
    "            url = \"https://simurg.iszf.irk.ru/tecs/\"+query['paths']['data']\n",
    "            urlretrieve(url, os.path.join(directory,file_name), reporthook=progress_print)\n",
    "        else:\n",
    "            url = \"https://simurg.iszf.irk.ru/tecs/\"+query['paths']['zippng']\n",
    "            urlretrieve(url, os.path.join(directory,file_name), reporthook=progress_print)\n",
    "        if file_name in os.listdir():\n",
    "            return print(\"Downloaded as \"+file_name+\"!\")\n",
    "        else:\n",
    "            return print(\"Mistake occurs!\")\n",
    "    else:\n",
    "        return print(\"Nothing to Download!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00c2d574-81b2-42f3-a190-f802281cc9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03de62d2-b023-4f46-80fa-b8fd0bd8d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_query_by_mail(mail):\n",
    "    \"\"\"\n",
    "    Return last query ID or None if there are no queries\n",
    "    \"\"\"\n",
    "    resp = requests.post(\"https://simurg.iszf.irk.ru/api\", \n",
    "                         json={\"method\": \"check\", \n",
    "                               \"args\": {\"email\": mail}\n",
    "                              }\n",
    "                        )\n",
    "    queries = resp.json()\n",
    "    last = datetime(1970,1,1)\n",
    "    _id = None\n",
    "    for q in queries:\n",
    "        datetime_str = q['created'][:19]\n",
    "        t = datetime.strptime(datetime_str, '%Y-%m-%d %H:%M:%S')\n",
    "        last = max(t, last)\n",
    "        if last == t:\n",
    "            _id = q['id']\n",
    "    return _id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0537eab5-f167-4e93-9ba1-33493b9bdcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_query_is_done(mail, _id, timeout = 600, delete=True, download=False):\n",
    "    st = time.time()\n",
    "    done = False\n",
    "    while True:\n",
    "        rq = requests.post(\"https://simurg.iszf.irk.ru/api\", \n",
    "                           json={\"method\": \"check\", \"args\": {\"email\": mail}}\n",
    "                          )\n",
    "        queries = rq.json()\n",
    "        for q in queries:\n",
    "            if _id == q['id']:\n",
    "                status = q['status']\n",
    "                print(f'Query {_id} status is {status}')\n",
    "                if q['status'] in ['done', 'failed']:\n",
    "                    done = True\n",
    "        if done:\n",
    "            break\n",
    "        if time.time() - st > timeout:\n",
    "            break\n",
    "        time.sleep(60)\n",
    "    if done == True:\n",
    "        if delete == True:\n",
    "            resp = requests.post(\"https://simurg.iszf.irk.ru/api\", \n",
    "                                  json={\"method\": \"delete\", \"args\": {\"id\": _id}}\n",
    "                                )\n",
    "            if resp.ok:\n",
    "                print(f'Deleted DONE {_id}')\n",
    "            else:\n",
    "                print(f'Failed to delete {_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07176619-d484-4436-9451-99f3279dc323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_long_series(start, end, step, mail, site):\n",
    "    tformat = '%Y-%m-%d %H:%M'\n",
    "    tfrom = start\n",
    "    while tfrom < end:\n",
    "        try:\n",
    "            till = tfrom + step\n",
    "            query_args = {\"email\": mail, \n",
    "                      \"begin\": tfrom.strftime(tformat), \n",
    "                      \"end\": till.strftime(tformat), \n",
    "                      \"site\": site,\n",
    "                      \"flags\": {\"notification\": False}\n",
    "                     }\n",
    "            print(f'STARTING query from {tfrom} to {till}')\n",
    "            resp = requests.post(\"https://simurg.iszf.irk.ru/api\", \n",
    "                             json={\"method\": \"create_series\", \"args\": query_args})\n",
    "\n",
    "            if resp.ok:\n",
    "                print(f'CREATED query from {tfrom} to {till}')\n",
    "                _id = get_last_query_by_mail(mail)\n",
    "                wait_query_is_done(mail, _id, delete=True)\n",
    "            else:\n",
    "                print(f'FAILED TO query from {tfrom} to {till}')\n",
    "                print(resp.text)\n",
    "            tfrom = till\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9652403b-ac1a-4d63-b7bc-4a20932da6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING query from 2015-01-01 00:00:00 to 2015-01-03 23:59:59\n",
      "CREATED query from 2015-01-01 00:00:00 to 2015-01-03 23:59:59\n",
      "STARTING query from 2015-01-03 23:59:59 to 2015-01-06 23:59:58\n",
      "CREATED query from 2015-01-03 23:59:59 to 2015-01-06 23:59:58\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = datetime(2015, 1, 1)\n",
    "end = datetime(2015, 12, 31)\n",
    "step = timedelta(3, 0) - timedelta(0, 1)\n",
    "MAIL = \"your@mail.com\"                \n",
    "run_long_series(start, end, step, MAIL, 'irkj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae38aa-e233-477f-8341-e182bc4b3f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
