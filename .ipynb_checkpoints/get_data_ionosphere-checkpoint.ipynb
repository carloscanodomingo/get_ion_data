{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f55e4fa-af8c-45fa-98c6-b2405992bd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from multiprocessing import Process, Pool\n",
    "from dateutil.relativedelta import *\n",
    "import dateutil.parser\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fc5210b-6f5d-4094-95ce-110bf12208f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPS_info = pd.read_csv(\"IGSNetwork.csv\")\n",
    "df_stations = GPS_info[\"#StationName\"].copy()\n",
    "df_lat = GPS_info[\"Latitude\"].array\n",
    "df_long =  GPS_info[\"Longitude\"].array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d0e2fe5-d698-4afa-b647-9962767763db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance between China Shangai and Max Hermosillo is:  9386.237724873392\n"
     ]
    }
   ],
   "source": [
    "# Import the geodesic module from geopy library \n",
    "from geopy.distance import geodesic as GD\n",
    " # For the specified locations, load their latitude and longitude data.\n",
    "china_coor = (37.970250, 23.722544)#(31.19, 121.50)\n",
    "mex_coor  = (29.08, -110.96)\n",
    "closest_stations_n = 8\n",
    "#Finally, print the distance between the two sites in kilometers.\n",
    "print(\"The distance between China Shangai and Max Hermosillo is: \", GD(china_coor,mex_coor).km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c265959-ab72-4b73-8ecb-40615bd53eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_china = pd.DataFrame({\"CHINA_DIST\":[GD((current_lat, current_lot),china_coor).km for (current_lat, current_lot) in zip(df_lat,df_long)]})\n",
    "df_mex = pd.DataFrame({\"MEX_DIST\":[GD((current_lat, current_lot),mex_coor).km for (current_lat, current_lot) in zip(df_lat,df_long)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5c54a86-3d28-4833-a8ee-53b1a3cc2123",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.concat([df_stations, df_china.reindex(df_stations.index), df_mex.reindex(df_stations.index)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "591bab31-9c24-4267-bce2-219a94988231",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_china = stations.sort_values(by=\"CHINA_DIST\")[0:closest_stations_n].index\n",
    "index_mex = stations.sort_values(by=\"MEX_DIST\")[0:closest_stations_n].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e09ad01-419c-4023-9871-edc87628f056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([277, 465, 68, 278, 442, 443, 180, 396, 112, 183, 311, 399, 182,\n",
       "            444, 242, 244],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_china.append(index_mex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5505a533-fe7c-4459-8117-5cb9825ea3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    #StationName   CHINA_DIST     MEX_DIST\n",
      "277    MSSA00JPN    93.269342  9406.361252\n",
      "465    USUD00JPN    93.597608  9407.548312\n",
      "68     CHOF00JPN   184.481644  9518.564662\n",
      "278    MTKA00JPN   187.193284  9520.107406\n",
      "442    TSK200JPN   239.067502  9520.527115\n",
      "443    TSKB00JPN   239.067502  9520.527115\n",
      "180    ISHI00JPN   253.037202  9520.861902\n",
      "396    SMST00JPN   272.673766  9441.334122\n",
      "112    DYNG00GRC  9364.471945    21.998436\n",
      "183    IZMI00TUR  9132.432900   298.070372\n",
      "311    ORID00MKD  9335.737707   431.445158\n",
      "399    SOFI00BGR  9069.157841   509.961189\n",
      "182    ISTA00TUR  8814.001250   572.848723\n",
      "444    TUBI00TUR  8807.223772   584.112065\n",
      "242    MAT100ITA  9619.052021   674.080016\n",
      "244    MATG00ITA  9619.052021   674.080016\n"
     ]
    }
   ],
   "source": [
    "current_stations = stations.iloc[index_china.append(index_mex),:]\n",
    "print(current_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "12b6c7a1-4116-48f6-92f5-f2261625c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pre_path = \"D://dataframe\"\n",
    "file_name = \"{station}_{year}_{month}_{day}.csv\"\n",
    "headers = ['dates', 'tec']\n",
    "dtypes = {'dates': 'str', 'tec': 'float'}\n",
    "parse_dates = ['dates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "251c9d36-ef8c-40e8-8b5e-97beaec2f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_and_erase(path, station):\n",
    "    headers = ['dates', 'tec']\n",
    "    dtypes = {'dates': 'str', 'tec': 'float'}\n",
    "    parse_dates = ['dates']\n",
    "    df_output = pd.DataFrame()\n",
    "    for file in Path(\".\").glob(\"*{station}*\".format(station=station)):\n",
    "        with file as f:\n",
    "            current_df_output = pd.read_csv(f, header=None,  comment='#',sep = ' ',names=headers, dtype=dtypes, parse_dates=parse_dates)\n",
    "            current_df_output = current_df_output.set_index(\"dates\")\n",
    "            df_output = pd.concat([df_output, current_df_output])\n",
    "        df_output.to_csv(path , compression = 'xz')\n",
    "        file.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "098f4762-4cb9-4bf3-8dd5-819bee1385d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return None if hte file is in the fs\n",
    "def get_new_path(day, station):\n",
    "    current_year = day.strftime('%Y')\n",
    "    current_month = day.strftime('%m')\n",
    "    current_path = pre_path + \"/\" + str(station) \n",
    "    current_path_year = current_path + \"/\" + current_year\n",
    "    current_path_year_month = current_path_year + \"/\" + current_month\n",
    "    current_path_year_day = current_path_year_month + \"/\" + file_name.format(station=station, year = current_year, month=current_month, day = day.strftime('%d'))\n",
    "    \n",
    "    if  Path(current_path).is_dir():\n",
    "        if  Path(current_path_year).is_dir():\n",
    "            if Path(current_path_year_month).is_dir():\n",
    "                if Path(current_path_year_day).is_file():\n",
    "                    return None\n",
    "                else:\n",
    "                    return current_path_year_day\n",
    "            else:\n",
    "                os.mkdir(current_path_year_month)\n",
    "                return current_path_year_day\n",
    "        else:\n",
    "            os.mkdir(current_path_year)\n",
    "            os.mkdir(current_path_year_month)\n",
    "            return current_path_year_day\n",
    "    else:\n",
    "        os.mkdir(current_path)\n",
    "        os.mkdir(current_path_year)\n",
    "        os.mkdir(current_path_year_month)\n",
    "        return current_path_year_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18a3dbad-a5fd-48d8-ace9-cbadbaf2ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tec_station(start_day, end_day, station):\n",
    "    all_days = [start_day+timedelta(days=x) for x in range((end_day-start_day).days)]\n",
    "    for day in all_days:\n",
    "        current_year = day.year\n",
    "        current_month = day.month\n",
    "        new_path = get_new_path(day, station)\n",
    "        if new_path != None:\n",
    "            print(str(station) + \" -- \" + str(day.strftime('%Y-%m-%d')))\n",
    "            result = subprocess.run([\"ionolabtec.exe\", str(station), str(day.strftime('%Y-%m-%d'))], capture_output=True)\n",
    "            if \"does not exist.\\\\r\\\\n\" in str(result.stdout):\n",
    "                print(str(station) + \" is not valid\")\n",
    "            read_csv_and_erase(new_path, station)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d860202-c312-4a13-8b40-cd2c8b2006a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USUD00JPN -- 2017-01-01TSK200JPN -- 2017-01-01CHOF00JPN -- 2017-01-01\n",
      "MSSA00JPN -- 2017-01-01\n",
      "\n",
      "ISHI00JPN -- 2017-01-01\n",
      "\n",
      "SMST00JPN -- 2017-01-01\n",
      "DYNG00GRC -- 2017-01-01\n",
      "MTKA00JPN -- 2017-01-01\n",
      "TSKB00JPN -- 2017-01-01IZMI00TUR -- 2017-01-01\n",
      "\n",
      "MTKA00JPN is not valid\n",
      "MTKA00JPN -- 2017-01-02\n",
      "TSKB00JPN is not valid\n",
      "TSKB00JPN -- 2017-01-02\n",
      "IZMI00TUR is not valid\n",
      "IZMI00TUR -- 2017-01-02\n",
      "MSSA00JPN is not valid\n",
      "MSSA00JPN -- 2017-01-02\n",
      "SMST00JPN is not valid\n",
      "SMST00JPN -- 2017-01-02\n",
      "CHOF00JPN is not valid\n",
      "CHOF00JPN -- 2017-01-02\n",
      "USUD00JPN is not valid\n",
      "USUD00JPN -- 2017-01-02\n",
      "ISHI00JPN -- 2017-01-02\n",
      "DYNG00GRC -- 2017-01-02\n",
      "TSK200JPN -- 2017-01-02\n",
      "DYNG00GRC -- 2017-01-03\n",
      "DYNG00GRC -- 2017-01-04\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import urllib.request\n",
    "from geopy.distance import geodesic as GD\n",
    "stations =  list(df_stations[0:10])\n",
    "stations = current_stations[\"#StationName\"]\n",
    "def f(station):\n",
    "    start_day = datetime(2016, 1, 1).date()\n",
    "    end_day = datetime(2016, 1, 5).date()\n",
    "    get_tec_station(start_day,end_day, station)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers = 10) as executor:\n",
    "\n",
    "    future_to_url = {executor.submit(f, station): station for station in stations}\n",
    "    for future in concurrent.futures.as_completed(future_to_url):\n",
    "        url = future_to_url[future]\n",
    "        try:\n",
    "            data = future.result()\n",
    "        except Exception as exc:\n",
    "            print('%r generated an exception: %s' % (url, exc))\n",
    "        else:\n",
    "            print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "67f7faea-52eb-4a15-b1d9-43be2d9abe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Including necessary packages\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7d7e4fa9-7f74-4fd8-90f7-0d27d5243824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking on queries function\n",
    "def checking_by_mail(mail):\n",
    "    \"\"\"\n",
    "    checking all accessible information about queries made by <mail>\n",
    "    input - <mail> string type email address to check\n",
    "    output - list of dictionaries with all information about every query\n",
    "    \"\"\"\n",
    "    rq = requests.post(\"https://simurg.iszf.irk.ru/api\", \n",
    "                        json={\"method\": \"check\", \n",
    "                        \"args\": {\"email\": mail}\n",
    "                              }\n",
    "                        )\n",
    "    return rq.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33dcd321-d7b2-4050-b3cf-30c9e569568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing results for email\n",
    "email = 'ccd532@uma.es'\n",
    "for i in checking_by_mail(email):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73da268c-89ef-4008-a60b-8d55ab3dbcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to show progrees of downloading data\n",
    "def progress_print(count, block_size, total_size):\n",
    "    prc = (count * block_size) / (total_size / 100)\n",
    "    print(\"{0:3d}/100%\".format(int(prc)), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96de05e3-5875-4952-82ec-3301f93ba694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to downloading data in same path as notebook \n",
    "def download_data(query,type_q,download_t):\n",
    "    \"\"\"\n",
    "    downloading data based on query dictionary\n",
    "    input - <query> query dictionary, \n",
    "            <type_q> string type what type of query download (either 'series' or 'map'), \n",
    "            <download_t> string type what to download ('zip' zip archive of maps/series or 'h5' all data in hdf type)\n",
    "    output - Results of downloading\n",
    "    \"\"\"    \n",
    "    print('id:', query['id'],\n",
    "          'type:', query['type'],\n",
    "          'status:', query['status'],\n",
    "          'site:', query['site'])\n",
    "    if query['type'] == type_q and query['status'] == 'done':\n",
    "        directory = os.getcwd()\n",
    "        file_name = 'example.'+download_t\n",
    "        if download_t == 'h5':\n",
    "            url = \"https://simurg.iszf.irk.ru/tecs/\"+query['paths']['data']\n",
    "            urlretrieve(url, os.path.join(directory,file_name), reporthook=progress_print)\n",
    "        else:\n",
    "            url = \"https://simurg.iszf.irk.ru/tecs/\"+query['paths']['zippng']\n",
    "            urlretrieve(url, os.path.join(directory,file_name), reporthook=progress_print)\n",
    "        if file_name in os.listdir():\n",
    "            return print(\"Downloaded as \"+file_name+\"!\")\n",
    "        else:\n",
    "            return print(\"Mistake occurs!\")\n",
    "    else:\n",
    "        return print(\"Nothing to Download!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00c2d574-81b2-42f3-a190-f802281cc9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03de62d2-b023-4f46-80fa-b8fd0bd8d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_query_by_mail(mail):\n",
    "    \"\"\"\n",
    "    Return last query ID or None if there are no queries\n",
    "    \"\"\"\n",
    "    resp = requests.post(\"https://simurg.iszf.irk.ru/api\", \n",
    "                         json={\"method\": \"check\", \n",
    "                               \"args\": {\"email\": mail}\n",
    "                              }\n",
    "                        )\n",
    "    queries = resp.json()\n",
    "    last = datetime(1970,1,1)\n",
    "    _id = None\n",
    "    for q in queries:\n",
    "        datetime_str = q['created'][:19]\n",
    "        t = datetime.strptime(datetime_str, '%Y-%m-%d %H:%M:%S')\n",
    "        last = max(t, last)\n",
    "        if last == t:\n",
    "            _id = q['id']\n",
    "    return _id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0537eab5-f167-4e93-9ba1-33493b9bdcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_query_is_done(mail, _id, timeout = 600, delete=True, download=False):\n",
    "    st = time.time()\n",
    "    done = False\n",
    "    while True:\n",
    "        rq = requests.post(\"https://simurg.iszf.irk.ru/api\", \n",
    "                           json={\"method\": \"check\", \"args\": {\"email\": mail}}\n",
    "                          )\n",
    "        queries = rq.json()\n",
    "        for q in queries:\n",
    "            if _id == q['id']:\n",
    "                status = q['status']\n",
    "                print(f'Query {_id} status is {status}')\n",
    "                if q['status'] in ['done', 'failed']:\n",
    "                    done = True\n",
    "        if done:\n",
    "            break\n",
    "        if time.time() - st > timeout:\n",
    "            break\n",
    "        time.sleep(60)\n",
    "    if done == True:\n",
    "        if delete == True:\n",
    "            resp = requests.post(\"https://simurg.iszf.irk.ru/api\", \n",
    "                                  json={\"method\": \"delete\", \"args\": {\"id\": _id}}\n",
    "                                )\n",
    "            if resp.ok:\n",
    "                print(f'Deleted DONE {_id}')\n",
    "            else:\n",
    "                print(f'Failed to delete {_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07176619-d484-4436-9451-99f3279dc323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_long_series(start, end, step, mail, site):\n",
    "    tformat = '%Y-%m-%d %H:%M'\n",
    "    tfrom = start\n",
    "    while tfrom < end:\n",
    "        try:\n",
    "            till = tfrom + step\n",
    "            query_args = {\"email\": mail, \n",
    "                      \"begin\": tfrom.strftime(tformat), \n",
    "                      \"end\": till.strftime(tformat), \n",
    "                      \"site\": site,\n",
    "                      \"flags\": {\"notification\": False}\n",
    "                     }\n",
    "            print(f'STARTING query from {tfrom} to {till}')\n",
    "            resp = requests.post(\"https://simurg.iszf.irk.ru/api\", \n",
    "                             json={\"method\": \"create_series\", \"args\": query_args})\n",
    "\n",
    "            if resp.ok:\n",
    "                print(f'CREATED query from {tfrom} to {till}')\n",
    "                _id = get_last_query_by_mail(mail)\n",
    "                wait_query_is_done(mail, _id, delete=True)\n",
    "            else:\n",
    "                print(f'FAILED TO query from {tfrom} to {till}')\n",
    "                print(resp.text)\n",
    "            tfrom = till\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9652403b-ac1a-4d63-b7bc-4a20932da6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING query from 2015-01-01 00:00:00 to 2015-01-03 23:59:59\n",
      "CREATED query from 2015-01-01 00:00:00 to 2015-01-03 23:59:59\n",
      "STARTING query from 2015-01-03 23:59:59 to 2015-01-06 23:59:58\n",
      "CREATED query from 2015-01-03 23:59:59 to 2015-01-06 23:59:58\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = datetime(2015, 1, 1)\n",
    "end = datetime(2015, 12, 31)\n",
    "step = timedelta(3, 0) - timedelta(0, 1)\n",
    "MAIL = \"your@mail.com\"                \n",
    "run_long_series(start, end, step, MAIL, 'irkj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae38aa-e233-477f-8341-e182bc4b3f12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
